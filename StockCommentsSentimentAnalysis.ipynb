{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Stocks Data Sentiment Analysis.</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing Stocks Comments Model.</h3>\n",
    "<p>Using the pandas load stocks_data csv file.<br>\n",
    "    Looking Head\n",
    "    <table>\n",
    "        <tr>\n",
    "            <th>Text</th>\n",
    "            <th>Sentiment</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Stocks Comments Data. Need to purify this comments. This Comment will be very helpful to predict the stock to invest.</td>\n",
    "            <td>Positive/Negative</td>\n",
    "        </tr>\n",
    "        </table>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_data  = pd.read_csv('stock_data.csv')\n",
    "stocks_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ethender/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5791"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stocks_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cleaning The Data.</h3>\n",
    "<p>Cleaning english stopwords. changing words to past, future to present words.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0,5791):\n",
    "    review = re.sub('[^a-zA-Z]',' ',stocks_data['Text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ''.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <ul>\n",
    "        <li>Above checking every word.</li>\n",
    "        <li>Every word checks removing vocabulary word.</li>\n",
    "        <li>Changing Past/Future to Present word.</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <ol>\n",
    "        <li>X : Cleaned words is ready to send machine learning to predict.</li>\n",
    "        <li>Y : Positive words / Negative words</li>\n",
    "    </ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=2000)\n",
    "x = cv.fit_transform(corpus).toarray()\n",
    "y = stocks_data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 619,    0],\n",
       "       [1109,   10]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3619102416570771"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 614,    5],\n",
       "       [1110,    9]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train,y_train)\n",
    "y_knn_pred = knn.predict(x_test)\n",
    "confusion_matrix(y_test,y_knn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <ul>\n",
    "        <li>After converting words &amp; further processing data.</li>\n",
    "        <li>Feeding into the machine learning models.</li>\n",
    "        <li>But accuracy still not high. Need further changes.</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Alternate way changing.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(stocks_data['Text'],stocks_data.iloc[:,-1].values,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <ul>\n",
    "        <li>Written new class.</li>\n",
    "        <li>Taking Every word.</li>\n",
    "        <li>Converting every word to lowercase.</li>\n",
    "        <li>Converting every number to number literal.</li>\n",
    "        <li>Removing every punctuation on the word.</li>\n",
    "        <li>Now appliying past/future to present.</li>\n",
    "        <li>Returning changing words.</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from collections import Counter\n",
    "\n",
    "stemmer = nltk.PorterStemmer()\n",
    "\n",
    "class WordCounterTranformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,strip_headers=True,lower_case=True,remove_punctuation=True,\n",
    "                replace_urls=True,replace_numbers=True,stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    \n",
    "    def fit(self,x,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,x,y=None):\n",
    "        x_transformed = []\n",
    "        for email in x:\n",
    "            text = email or ''\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?','NUMBER',text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+',' ',text,flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            x_transformed.append(word_counts)\n",
    "        return np.array(x_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'number': 2, 'ove': 1, 'gnw': 1, 'call': 1, 'are': 1, 'make': 1, 'me': 1, 'feel': 1, 'better': 1, 'about': 1, 'myself': 1, 'for': 1, 'not': 1, 'dump': 1, 'aap': 1, 'sooner': 1}),\n",
       "       Counter({'number': 6, 'jan': 2, 'csn': 1, 'option': 1, 'trader': 1, 'buy': 1, 'of': 1, 'the': 1, 'call': 1, 'spread': 1, 'against': 1, 'low': 1, 'oi': 1, 'indic': 1, 'enter': 1, 'a': 1, 'posit': 1, 'for': 1, 'bet': 1, 'on': 1, 'data': 1, 'bef': 1}),\n",
       "       Counter({'and': 2, 'peopl': 1, 'slag': 1, 'aap': 1, 'for': 1, 'cannib': 1, 'but': 1, 'samsung': 1, 'ha': 1, 'number': 1, 'phone': 1, 'no': 1, 'cult': 1, 'or': 1, 'itun': 1, 'it': 1, 'is': 1, 'the': 1, 'new': 1, 'cool': 1, 'idontthinkso': 1}),\n",
       "       ...,\n",
       "       Counter({'have': 2, 'rt': 1, 'jchengwsj': 1, 'in': 1, 'hindsight': 1, 'wall': 1, 'street': 1, 'probabl': 1, 'shouldn': 1, 't': 1, 'let': 1, 'luckin': 1, 'coffe': 1, 's': 1, 'chairman': 1, 'more': 1, 'or': 1, 'less': 1, 'unfett': 1, 'access': 1, 'to': 1, 'half': 1, 'aâ': 1}),\n",
       "       Counter({'the': 2, 'global': 1, 'stock': 1, 'fall': 1, 'after': 1, 'presid': 1, 'trump': 1, 'issu': 1, 'a': 1, 'new': 1, 'warn': 1, 'on': 1, 'spread': 1, 'of': 1, 'coronaviru': 1, 'in': 1, 'u': 1, 's': 1, 'http': 1, 't': 1, 'co': 1, 'anumberigwnumbernefq': 1}),\n",
       "       Counter({'hpq': 1, 'how': 1, 'mani': 1, 'upgrad': 1, 'tomorrow': 1, 'assum': 1, 'autonomi': 1, 'is': 1, 'now': 1, 'worth': 1, 'someth': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_few_wordcounts = WordCounterTranformer().fit_transform(x_train)\n",
    "x_few_wordcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "        <ul>\n",
    "            <li>Below class written for checking every word.</li>\n",
    "            <li>Checking every word and count.</li>\n",
    "            <li>Final, returning csr_matrix means <b>sparse matrix.</b></li>\n",
    "        </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b>What is sparse matrix?</b><br>\n",
    "    In numerical analysis and scientific computing, a sparse matrix or sparse array is a matrix in which most of the elements are zero. By contrast, if most of the elements are nonzero, then the matrix is considered dense.\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td>5</td>\n",
    "            <td>0</td>\n",
    "            <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>0</td>\n",
    "            <td>12</td>\n",
    "            <td>0</td>\n",
    "        </tr>\n",
    "         <tr>\n",
    "            <td>0</td>\n",
    "            <td>0</td>\n",
    "            <td>47</td>\n",
    "        </tr>\n",
    "        </table>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, x, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in x:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] +=  min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.most_common = most_common\n",
    "        self.vocabulary_ = {word: index +1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self,x,y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(x):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word,0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data,(rows,cols)),shape=(len(x),self.vocabulary_size+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4632x11 sparse matrix of type '<class 'numpy.longlong'>'\n",
       "\twith 14593 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "x_few_vectors = vocab_transformer.fit_transform(x_few_wordcounts)\n",
    "x_few_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  2,  0, ...,  1,  1,  0],\n",
       "       [17,  6,  1, ...,  0,  1,  0],\n",
       "       [18,  1,  1, ...,  1,  1,  0],\n",
       "       ...,\n",
       "       [21,  0,  0, ...,  0,  0,  1],\n",
       "       [16,  0,  2, ...,  0,  0,  1],\n",
       "       [11,  0,  0, ...,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    ('text_wordcount', WordCounterTranformer()),\n",
    "    ('wordcount_to_vector', WordCounterToVectorTransformer()),\n",
    "])\n",
    "x_train_transformed = preprocess_pipeline.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Machine Learning Models.</h2>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>Checking Logistic Regression.</li>\n",
    "        <li>Cross-Validation &amp; Making 3 epochs.</li>\n",
    "        <li>These shows 77% accuracy.</li>\n",
    "        <li>Precision: 80.46%.  Means 80.46% correctly Stocks 1 predicted.</li>\n",
    "        <li>Recall: 86.07%. Means 86.07% correctly Stocks 0 predicted.</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.760, total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.765, total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.775, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7666234887737479"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_clf = LogisticRegression(solver='lbfgs',random_state=42)\n",
    "score = cross_val_score(log_clf,x_train_transformed,y_train,cv=3,verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisions: 80.46%\n",
      "Recall: 86.07%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "x_test_transformed = preprocess_pipeline.transform(x_test)\n",
    "\n",
    "log_clf = LogisticRegression(solver='lbfgs',random_state=42)\n",
    "log_clf.fit(x_train_transformed,y_train)\n",
    "\n",
    "y_pred = log_clf.predict(x_test_transformed)\n",
    "print('Precisions: {:.2f}%'.format(100*precision_score(y_test,y_pred)))\n",
    "print('Recall: {:.2f}%'.format(100*recall_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bagging Classifier.</h2>\n",
    "<p>\n",
    "    Bagging Classifier will be helpful to train multiple set of samples and estimating.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(),n_estimators=500,\n",
    "    max_samples=100,bootstrap=True,n_jobs=-1,oob_score=True)\n",
    "bag_clf.fit(x_train_transformed,y_train)\n",
    "y_pred = bag_clf.predict(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7083692838654012"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6996977547495682"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Ensemble Method</h2>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>Ensemble method will be combine of multiple machine learning algorithms.</li>\n",
    "        <li>These will be helpful. Combining all results show final better result.</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('log', LogisticRegression(random_state=42)),\n",
       "                             ('rnd', RandomForestClassifier(random_state=42)),\n",
       "                             ('svm', SVC(probability=True, random_state=42)),\n",
       "                             ('knn', KNeighborsClassifier()),\n",
       "                             ('tree', DecisionTreeClassifier())],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver='lbfgs',random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "svm_clf = SVC(gamma='scale',probability=True,random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "decision_clf = DecisionTreeClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('log',log_clf),\n",
    "                                         ('rnd',rnd_clf),\n",
    "                                         ('svm',svm_clf),\n",
    "                                         ('knn',knn),\n",
    "                                         ('tree',decision_clf)],\n",
    "                             voting='soft')\n",
    "voting_clf.fit(x_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7799827437446074\n",
      "Precisions: 80.46%\n",
      "Recall: 86.07%\n",
      "RandomForestClassifier 0.7972389991371872\n",
      "Precisions: 82.48%\n",
      "Recall: 86.20%\n",
      "SVC 0.7791199309749784\n",
      "Precisions: 77.36%\n",
      "Recall: 91.94%\n",
      "KNeighborsClassifier 0.6937014667817084\n",
      "Precisions: 73.36%\n",
      "Recall: 80.87%\n",
      "DecisionTreeClassifier 0.724762726488352\n",
      "Precisions: 78.88%\n",
      "Recall: 77.05%\n",
      "VotingClassifier 0.7937877480586712\n",
      "Precisions: 81.72%\n",
      "Recall: 86.75%\n"
     ]
    }
   ],
   "source": [
    "for clf in (log_clf,rnd_clf,svm_clf,knn,decision_clf,voting_clf):\n",
    "    clf.fit(x_train_transformed,y_train)\n",
    "    y_pred = clf.predict(x_test_transformed)\n",
    "    print(clf.__class__.__name__,accuracy_score(y_test,y_pred))\n",
    "    print('Precisions: {:.2f}%'.format(100*precision_score(y_test,y_pred)))\n",
    "    print('Recall: {:.2f}%'.format(100*recall_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
